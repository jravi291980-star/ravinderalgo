# dhan_workers.py - Runs on the Worker Dyno to maintain two persistent WebSocket connections
import redis
import json
import os
import time
import threading
from dhanhq import DhanContext, MarketFeed, OrderUpdate, dhanhq
from datetime import datetime
from typing import Dict, List, Any

# --- Configuration Constants (Must match Django settings) ---
REDIS_URL = os.environ.get('REDIS_URL', 'redis://localhost:6379/0')
REDIS_DATA_CHANNEL = 'dhan_market_data'
REDIS_ORDER_UPDATE_CHANNEL = 'dhan_order_update'
REDIS_STATUS_DATA_ENGINE = 'data_engine_status'
REDIS_DHAN_TOKEN_KEY = 'dhan_access_token'
SYMBOL_ID_MAP_KEY = 'dhan_instrument_map'  # Key where management command stores the map

CLIENT_ID = os.environ.get('DHAN_CLIENT_ID', 'YOUR_CLIENT_ID')
r = redis.from_url(REDIS_URL, decode_responses=True)

# Global list of instruments to subscribe, populated at runtime
INSTRUMENTS_TO_SUBSCRIBE: List[tuple] = []


def get_dhan_context(client_id: str, token: str) -> Optional[DhanContext]:
    """Creates DhanContext object."""
    if not token:
        return None
    return DhanContext(client_id, token)


def get_current_token() -> Optional[str]:
    """Retrieves the latest access token from Redis."""
    return r.get(REDIS_DHAN_TOKEN_KEY)


def fetch_security_id_mapping() -> List[tuple]:
    """
    Loads the pre-calculated Symbol -> Security ID map from Redis (stored by management command)
    and constructs the subscription list for MarketFeed.
    """
    global SYMBOL_TO_SECURITY_ID, SECURITY_ID_TO_SYMBOL

    subscription_list = []

    try:
        # Load the instrument map generated by the management command
        instrument_map_raw = r.get(SYMBOL_ID_MAP_KEY)
        if not instrument_map_raw:
            print(
                f"[{datetime.now()}] CRITICAL: Instrument map not found in Redis at key: {SYMBOL_ID_MAP_KEY}. Run management command.")
            return []

        instrument_map: Dict[str, Dict[str, Any]] = json.loads(instrument_map_raw)

        # Iterate through the cached instruments and build subscription tuples
        for symbol, data in instrument_map.items():
            security_id = data.get('security_id')
            exchange_segment = data.get('exchange_segment')

            if security_id and exchange_segment:
                # We subscribe to the Full Packet (MarketFeed.Full = 4)
                # to get the low-latency OHLC updates required for 1-minute candles.
                subscription_list.append((
                    exchange_segment,
                    security_id,
                    MarketFeed.Full
                ))

        print(f"[{datetime.now()}] Successfully loaded and mapped {len(subscription_list)} instruments from Redis.")
        return subscription_list

    except Exception as e:
        print(f"[{datetime.now()}] ERROR processing cached security list: {e}")
        return []


# --- Market Feed Worker (Runs in Thread 1) ---

def on_market_feed_message(instance: MarketFeed, message: Dict[str, Any]):
    """Callback for Market Feed: Publishes raw market data instantly to Redis channel."""
    try:
        # Publish the decoded market data immediately to the dedicated channel
        r.publish(REDIS_DATA_CHANNEL, json.dumps(message))
    except Exception as e:
        print(f"[{datetime.now()}] MarketFeed Error during publish: {e}")


def run_market_feed_worker(dhan_context: DhanContext):
    """Manages the MarketFeed WebSocket connection."""
    while True:
        try:
            print(
                f"[{datetime.now()}] MarketFeed: Attempting connection and subscribing to {len(INSTRUMENTS_TO_SUBSCRIBE)} symbols...")
            market_client = MarketFeed(
                dhan_context,
                INSTRUMENTS_TO_SUBSCRIBE,  # Use the dynamically populated list
                version="v2"
            )
            market_client.on_message = on_market_feed_message

            # This method blocks, maintaining the connection
            market_client.run_forever()

        except Exception as e:
            print(f"[{datetime.now()}] MarketFeed DOWN: {e}. Reconnecting in 10s...")
            # Ensure clean disconnection before retry
            try:
                # NOTE: The disconnect method might be instance specific,
                # wrap in try/except for robustness.
                market_client.disconnect()
            except:
                pass
            time.sleep(10)


# --- Order Update Worker (Runs in Thread 2) ---

def on_order_update_message(order_data: dict):
    """Callback for Order Updates: Publishes order status instantly to Redis channel."""
    try:
        # We need the "Data" part of the order update response structure
        # The Algo Engine relies on receiving this data for instant reconciliation
        r.publish(REDIS_ORDER_UPDATE_CHANNEL, json.dumps(order_data.get("Data", order_data)))
    except Exception as e:
        print(f"[{datetime.now()}] OrderUpdate Error during publish: {e}")


def run_order_update_worker(dhan_context: DhanContext):
    """Manages the Live Order Update WebSocket connection."""
    while True:
        try:
            print(f"[{datetime.now()}] OrderUpdate: Attempting connection...")
            order_client = OrderUpdate(dhan_context)
            order_client.on_update = on_order_update_message

            # This method blocks, maintaining the connection
            order_client.connect_to_dhan_websocket_sync()

        except Exception as e:
            print(f"[{datetime.now()}] OrderUpdate DOWN: {e}. Reconnecting in 10s...")
            time.sleep(10)


# --- Main Engine Control ---

def main_worker_loop():
    """Main function to manage initialization and run workers concurrently."""
    global INSTRUMENTS_TO_SUBSCRIBE

    r.set(REDIS_STATUS_DATA_ENGINE, 'STARTING')
    token = get_current_token()

    while not token:
        print(f"[{datetime.now()}] Waiting for Dhan Access Token in Redis (required for REST/WS).")
        time.sleep(5)
        token = get_current_token()

    dhan_context = get_dhan_context(CLIENT_ID, token)
    if not dhan_context:
        print("Fatal: Could not create Dhan Context. Check CLIENT_ID. Exiting.")
        r.set(REDIS_STATUS_DATA_ENGINE, 'FATAL_ERROR')
        return

    # --- CRITICAL STEP 1: Load instrument subscription list ---
    INSTRUMENTS_TO_SUBSCRIBE = fetch_security_id_mapping()

    if not INSTRUMENTS_TO_SUBSCRIBE:
        print("Fatal: No instruments were mapped. Check token and management command execution.")
        r.set(REDIS_STATUS_DATA_ENGINE, 'FATAL_ERROR_NO_INSTRUMENTS')
        return

    # --- CRITICAL STEP 2: Start both feeds in separate threads for low-latency concurrency ---
    market_thread = threading.Thread(target=run_market_feed_worker, args=(dhan_context,), daemon=True)
    order_thread = threading.Thread(target=run_order_update_worker, args=(dhan_context,), daemon=True)

    market_thread.start()
    order_thread.start()

    r.set(REDIS_STATUS_DATA_ENGINE, 'RUNNING')
    print(f"[{datetime.now()}] Data Engine Running: Both MarketFeed and OrderUpdate threads active.")

    # Keep the main thread alive, watching the status
    market_thread.join()
    order_thread.join()

    r.set(REDIS_STATUS_DATA_ENGINE, 'EXITED')


if __name__ == '__main__':
    main_worker_loop()